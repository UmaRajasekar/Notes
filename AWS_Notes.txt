Region and Availability Zone
------------------------------

Region is the geographical position
Availability Center is data center

Edge location is used to cache information from one data center to another data center

aws ec2 describe-regions
aws ec2 describe-availability-zones --region

Services in AWS
----------------
Compute
EC2-> Elastic Compute Cloud -> helps to create virtual machine
EC2 container service-> manages docker container
Elastic beanstalks -elastic band Stolk is basically for developers who don't understand AWOS and who just upload de-code elastic band Stoeckle then go through and provision things like orders scaling groups or load balances or two instances etc..
Lamda-> code you upload and control when to execute it
Lightsail-> Virtual Private services
Batch-> Running batch

Storage
S3-> refers three S. You have things called bucket. you upload files to bucket. Simple storage devices. Object based storage
EFS-> Elastic file storage. Stores file and can be mount to any virtual machine
Glacier-> This is for data archival
Snowball-> This is used to bring large amount of data into aws data center
Storage gateway-> Virtual machine you install in headoffice to store large amount of data

Databases
RDS-> Relation database services. Ex:Mysql
DynamoDB-> Non relational databases
Elasticache-> Used to cache queries from database services. This used to free up your database services
RedShift-> built for database warehousing which  can be used to query large database

Migration
AWS migration hub-> Tracking services which helps to track migration of application into aws. Integrates with other services in migration framework
Application discovery services-> automated set of tools which detects what application we have along with its dependencies. way of tracking dependencies for your application
Database Migration Service-> easiest way to migrate database from on-premise to cloud
Server Migration service-> migrates virtual and physical server into aws cloud
Snowball

Networking and Content Delivery
VPC-> Virtual Private Cload-> configure firewall, network availability zone, network side address range, network ACL and route tables
CloudFront-> Amazons content delivery network. cloudfront forms a cloud of distant location in nearby access loaction. This helps in easy download of media files
Route 53-> Amazon DNS service
API Gateway-> mainly involves in creating websites where you can create your own API where other service can talk to.
DirectConnect-> Its kind of running a line where it directly connects your PC

Developer Tools
CodeStar-> Project Managing a code where you get group of developer to work in that code and managing it.
CodeCommit-> This is the source control version of it
CodeBuild-> Once code is ready, this helps to compile and run test
CodeDeloy-> This is an automated deploymemt service of code. This also helps to deploy code in ec2 and on-premise instance
CodePipeline-> This helps to build a pipline
X-Ray-> This helps to analyse your code. helps in identifying issues and bottlenecks
Cloudnine-> This helps to develop code aws console rather than developing in your desktop

Managment Tools
CloudWatch->Important for sysops
CloudFormation->Important for Solution Artitect. Helps in setting up servers along with all firewalls using ansible code
CloudTrail->Logs changes to AWS environment
Config->Monitors configuration of aws environment
OpsWork->use chef and puppet to automate configuration of the environment
ServiceCatalog->Manages catalog of IT services. This could be virtual machines, machines, software and database etc.. used by big organisation for governence and complaince reaquirements.
System manager-> interface to manage all aws resources.ex: to rollout patches for whole sort of ec2-instances.
Trusted Advisor-> gives advice regarding security, usages and advice to save money  
Managed Services-> need not to worry about AC to instances and auto scaling

Media Services
Elastic Transcoder-> vedio recorded in aws will be re-sized so that it is capable to run in any devices
Media coonvert->Allows you to create vedios and broadcast
MediaLive-> High quality vedio is delivered to broadcast in tv and other internet services
MediaPackage-> helps in delivering vedio across internet 
MediaStore-> Helps in storing live and on-demand videos
MediaTailor->

MachineLearning
SageMaker-> easy use for developer. Used for deep learning mainly when coding for environments
Comprehend->centiment analysis of data which analysis whether people are saying good things about you or not
DeepLens-> artifical intelligence cameras which can figure out what it is looking at. We need a seperate hardware to do this.
Lex-> Way to connect customers. artificial intelligent chatbox
Machine Learning->Machine learning is different from deep learning where deep learning works on nuero network whereas machine learning works on entry level. Machine learning analys dataset we throw in and predicts the outcome from that
Polly-> turns text into speech
Rekognisition-> does vedio and images for you. Reads images and vedios into speech
Amazon Translate-> Machine language translate of amazon
Amazon Transcribe->recognizes speech and turns that into text

Analytics
Athena-> Allows you to run sql queries in S3 bucket(file system stored in s3 bucket)
EMR-> Elastic map reduce-> process large amount of data for big data solutions  
CloudSearch->search services
ElasticSearch->search services
Kinesis-> way of ingesting large amount of data in cloud
Kinesis vedio streams
QuickSight-> BI tool
DataPipeline-> Moving data across pipeline
Glue-> helps in ETL

Security, Identity and complaince
IAM-> Identity Access Management
Cognito->device authentication method
GaurdDuty->used to detect malacious activity in aws account
Inspector->agent stored in virtual machine and run whole bunch of test. Provides results on vulnerability
Macie->scans s3 bucket and identifies Personal Identity information
Certificate manager-> will get free SSL if we get registered with aws. manages SSL certificate
CloudHSM->Hardware security module-> Stores security key
Directory Service-> way of managing microsoft directory services
WAF-> Web application firewall ->
Sheild->helps to prevent DDOS attack
Artifact->portal to download aws complaince report

MobileServices
MobileHub->helps in connecting mobile app
Pinpoint-> helps in pushing notification to mobile
AWS AppSync-> used to upload data to mobile
DeviceFarm-> way of actually testing apps on real live devices
Mobile Analytics-> provides analytics for mobile application

AR/VR => Augmented reality. Virtual reality
Sumerian-> helps in creating 3D images/vedios

Application Integration
Step Function
Amazon MQ
SNS-> Notification service. if bill goes up, we can get notification in email/mobile
SQS-> decouples infrastructure. organizes queue
SWF-> Work flow system used by amazon marketing system

Customer Service
Connect->
Simple Email service

Business Productivity
Alexa for business
Chime-> used for amazon vedio conferencing like hangouts
WorkDocs-> like a dropbox
workMail-> like google mail

Desktop and Appstream
Workspaces->creates actual desktop environments
AppStream 2.0-> streaming actual application the application running in the cloud

IOT-> Internet of things
iot->
iot device management-> gives information on temperature, humidity, vedio stream. manages devices in internet
Amazon FreeRTOS->
Greengrass-> lets you run local computer messaging data caching sync and to machine learning interface capabilities for connected device in secure way.

GameDevelopement
GameLift-> Helps in creating games


Identity Access Management 101
Its about identifying your user, granting access and setting up the account
Gives centralized control of your AWS account
Shared access to your aws account
Granular Permission
Identity Federation
Multifactor Authentication
Provide temporary access to application
Allows you to set up own password rotation policy
Support PCI DSS Complaince

Critical Terms
Users
Group
Role-> create roles and assign them to aws resources
Policies-> document that defines one or more permissions

Comes under security, identity and complaince
IAM doesnt have region, thats why it is mentioned as global in top right corner
aws account name is customized->https://p727716.signin.aws.amazon.com/console
Multifactor Autentication-> MFA
root account-> email address, we logged on
For new users, access keys and secret key created can used to login using command line and api. access keys and secret key cannot be used to login via console. To login via console, we need to use password authenti
Always multifactor authentication account
can create password rotation policy

creating billing alaram
my billing dashboard

S3-101
S3-> 3S-> simple, storage and service
it provides IT team with secure, durable, highly-scalable object storage
with the help of simple web application, we can retrieve and store any large amount of data
Safe place to store your files
Obeject based storage(excludes OS, database and application)
Files from 0MB to 5TB can be stored
Files are stored in buckets(folders)
there is an unlimited storage available.
S3 is a universal namespace. Each bucket we create will have unique DNS/web address
if the upload is successful, we will recieve HTTP 200 code

Data consistency model for S3
Read after write consistency for PUTS of new Objects
Eventual consistency for overwrite PUTS and DELETES (can take some time to propagate)

S3 is a key value store.
Key-> name of the object
Value-> data in the object.
VersionId-> Important for versioning
Metadata-> Data about data
Subresources:
  Access Control List-> we can put individual permission
  Torrent
  
S3
Built for 99.99 percentage availability
Tired storage available
Life cycle management
Versioning
Encryption
Secure your data using access control list and bucket policies

S3-Storage Tiers/Classes
S3- Standard:
S3-IA(Infrequently accessed)-> for data accessed less frequently across multiple availability zone and retrival rate should be higher
S3-One zone - IA
Glacier-> used for archival process. Expedidited, Standard or Bulk. A standard retrival time takes 3-5 hours.

Transfer acceleration-> data from S3 bucket available in one region is moved to edge location(using amazon backbone) available near to user and user only use his internet service only to retrieve data from edge location

buckets are folder
objects are files
We manage bucket at global(region) level
bucket name should be unique as bucket name associates with DNS name
We will have seperate webaddress for each bucket
S3-Standard, S3-IA, S3 reduced redency
Encryption
client side encryption-> encrypt in desktop and upload
server side encryption-> with amazon s3-managed keys, with KMS, with customer provided keys
Control access to bucket using control ACL or using bucket policies
by default buckets are private and all objects stored inside are private

S3 versioning
Stores all versions of object (including all writes and even if you delete the object)
Great backup tool
Once enabled, versions cant be disabled but can be suspended
Integrates with life cycle rules
versioning MFA delete capability, which uses multi-factor authentication, can be used to provide an additional layer of security

S3Cross region replication
Version must be enabled in both source and destination
Regions must be unique
Files in an existing bucket will not be replicated automatically. All subsequent updated files will be replicated automatically.
You cannot replicate multiple buckets or use daisy chain
Delete markers are replicated
Deleting individual version or deleting markers will not be updated.
Understand what cross region replication at high level


1. Cross Referencing Replication of a bucket can be done by enabling versions
2. Replication Rule with prefixed with bucket option can be used to replicate only buckets having some folder name

User name: s3FullAccess
Access key ID: AKIAJRFTOWTYZ5DY5EFQ
Secret access key: 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
Console login link: https://p727716.signin.aws.amazon.com/console

aws configure -> to configure user
aws s3 ls -> lists all the s3 available for the user
aws s3 cp --recursive s3://p727716insurance s3://p727716insuranceuk -> copy files from source to target

Why life cycle management?
Life cycle management is used to manage your objects, automate transition of tiered storage and expire your object.
Transition is allowed only if the object is over 128KB and should be minimum of 30 days
Can be used in conjuction with versioning
can be applied to both current and previous version
Archival to glacier 30 days after standard IA
we can also permanently delete from glacier

CloudFront CDN overview
A content delivery network(CDN) is a system of distributed servers(network) that delivers web pages and other web content to a user based on the geographical location of the user , the origin of the website and a content delivery server
Edge Location- This is the location where the contents will be cached. This is seperate to AWS region/AZ
Origin- Origin is the origin of the file that the CDN will distribute. This can be either an S3 bucket, an EC2 instance, an Elastic Load Balance or Route 53
Distribution- This is the name given to CDN which consist collection of edge location.
Amazon CloudFront can be used to deliver your entire website, including dynamic, static, streaming and interactive content using global network of edge location, so contents are delivered with possible performance.
It is optimized to work with other Amazon web services, like Amazon simple stotage(S3), Amazon Elastic Cloud Coomputing(EC2), Amazon elastic load Balancing and Amazon Route53.
This also works seamlessly with other non-aws origin server, which stores original definitive version of the file.
Web distribution-Typically used for websites
RTMP- used for vedio streaming
Edge locations are not meant for read only. You can also write files. This gets refelected back to origin server
Objects are cached for the TTL (Time to Live)
You can also clear cache from edge location. But you will be charged.
Creating Distribution
*we can have multiple origin in a distribution with the help of origin path
*origin name will help us to distinguish the origin
*By restricting bucket access, we disable the public url generated and re-directs every request through cloudfront
*TTL is always in seconds
*Restrict viewer access option is to allow only authorised user can access the files 
*AWS WAF-> Web application firewall
*bucket name is expected to replace with

Securing your buckets
By default, all the buckets are private
You can setup access control to your buckets using following
*Bucket Policies
*Access Control Lists-> used to setup access for individual objects available in bucket
*We can acccess logs on actions performed on a particular bucket. We can also setup cross bucket access logs

Encryption
InTransit -> transferring file from local(desktop) to aws S3 bucket
  -SSL/TLS (https)
At Rest
  -Server side encryption
    *S3 Managed keys -SSE-S3
    *AWS Key Management Service, Managed keys -SSE-KMS
    *SSE with customer provided keys -SSE-C
  -Client side encryption
    *Customer encrypts the data before uploading to S3
    
Storage Gateway
 It is a service that connects an on-premises software appliance with cloud based storage to provide seamless and secure integration between an organization's on-premises IT environment and AWS storage infrastructure. This service enables you to securely store data to the AWS cloud for scalable and cost effective storage.
This is like a virtual client installed in IT environment to transfer data securely to cloud.
AWS storage gateway software appliance is available for download as a virtual machine (VM) image that you install on the host in your datacenter. Storage Gateway supports either VMware or Microsoft Hyper-V. Once you have installed your gateway and associated it with your AWS account through the activation process, you can use AWS Management console to create a storage gateway option that is right for you.
Four types of storage gateway
*File Gateway (NFS) -> allows you to store flat files in S3 like pdf, doc, pic  and vedios
*Volumes Gateway(iSCSI) -> block based storage. like VM running on virtual hard disk. Does not used for S3
  *Stored Volume
  *Cached Volume
Tape Gateway(VTL)-> mainly for archival solutions
creates virtual tapes and apply all archiving logics in S3

File Gateway
Files are stored as objects in your S3 buckets, accessed through network file system(NFS) mount point. Ownership, permissions, and timestamps are durably stored in S3 in the user-metadata of the object associated with the file. Once object are transferred to S3, they can be managed as native S3 objects, and bucket policies such as versioning, lifecycle management, and cross region replication apply directly to objects stored in your bucket.
Volume Gateway
The volume interface presents your applications with disk volumes using the iSCSI block protocol.
Data written to these volumes can be asynchronously backed up as point-in-time snapshots of your volumes, and stored in the cloud as Amazon EBS(Elastic Block Store) snapshots.
Snapshots are incremental backups that capture only changed blocks. All snapshot storage is also compressed to minimize your storage cost.
Stored Volumes
Stored Volumes let you store your primary data locally, while asynchronously backing up that data to AWS.
Stored volumes provides your on-premise applications with low latency access to thier entire datasets, while providing more durable, off-site backups.
You can create storage volumes and mount them to iSCSI devices from your on-premises application servers.
Data written to your stored volumes is stored on on-premises storage hardware
This data is asynchronously backed up to Amazon Simple Storage Service (Amazon S3) in the form of Amazon Elastic Block Store(Amazon EBS) snapshots.
1GB-16TB in size for Stored Volumes
Cached Volume
Cached Volume lets you use Amazon Simple Storage Service (Amazon S3) as your primary data storage while retaining frequently accessed data locally in your storage gateway.
This minimize the need to scale your on premises storage infrastructure, while still providing your application with low latency access to their frequently accessed data.
You can create storage volume upto 32 TB in size and attach to them as IsCSI devices from your on-premises application servers.
Your gateway stores data that you write to these volumes in Amazon S3 and retains recently read in your on-premise stotage gatway cache and upload buffer storage. 
1GB-32TB in size for cached volume
Tape Gateway
Tape Gateway offers a durable, cost-effective solution to archive your data in AWS cloud
The VTL interface provides it let you leverage your tape-based backup application infrastructure to store data on virtual tape cartliges  that you create on your tape gateway.
Each tape gateway is pre-configured with media changer and tape drives, which are available to your existing client backup applications as IsCSI device.
You add tape cartiliges as you need to archive your data.
Supported by NetBackup, BackUp Exec, Veeam etc.

Snowball
Before snowball, there is Import/Export Disk.
AWS Import/Export Disk accelerates moving large amount of data in and out of the AWS cloud using portable storage devices for transport.
AWS Import/Export Disk transfers your data directly onto and off of storage device using Amazon high speed internal network and bypassing the internet
Three types of snowball
*Standard Snowball
*SnowballEdge
*SnowMobile
Snowball is a petabyte-scale data transport solution that uses secure appliances to transfer large amount of data into and out of AWS.
Using snowball addresses common challanges with large scale data transfer including high network costs, long transfer claims and security concerns.
Transferring data with Snowball is simple,fast, secure and can be little as one-fifth of the cost of high-speed internet.
80TB snowball in all regions.
Snowball uses multiple layer of security designed to protect your data including tamper-resistent enclosures, 256-bitencryption and an Industrial-standard Trusted Platform Module (TPM) designed to ensure both security and full chain of security of the data. 
Once the data transfer job is processed and verified, AWS performs software erasure of the Snowball Appliance
SNowball Edge
this is 100TB data transfer device with on-board data storage and compute capabilities
You can use snowball edge to move large amount of data into and out of AWS as a temporary storage tier for large local datasets, or to support local workloads in remote or offline locations
Snowball edge connects to your existing applications and infrastructure using standard storage interface, streamlining data transfer process and minimizing setup and integration. 
SNowball edge can cluster together to form a local storage tier and process your data on-premises, helping ensure your applications continue to run even when they are not able to access the cloud
AWS Snowmobile
This is an exabyte-scale data transfer service used to move extremly large amount of data to AWS.
You can transfer upto 100PB per Snowmobile, a 45 foot long ruggedized shipping container pulled by a semi-trailer truck.
Snowmobile makes easy to move massive volume of data to the cloud, including vedio libraries, image repositories or even a complete data center migration. Transferring data with snowmobile is secure,fast and cost-effective.

S3 Transfer Acceleration
It uses cloud front edge network to accelerate your upload to S3.
Instead of directly uploading to S3 bucket, we can upload into edge location using a url which transfers to S3

EC2
Amazon Elastic Compute Cloud (EC2) is a web service that provides re-sizable compute capacity in the cloud. Amazon EC2 reduces the time required to obtain and boot new server instance to minutes, allowing you to scale capacity, both up and down, as your computing requirements change.
Amazon EC2 changes the ecnomy of computing by allowing you to pay only for the capacity that you actually use. Amazon Ec2 provides developers the tools to build failure resiliant applications and isolate themselves from common failure scenarios
EC2 Pricing Options
On Demand- allows you to pay fixed price by the hour (or by the second) with no commitment.
Reserved- provides you with a capacity reservation, and offer a significant discount on the hourly charge for an instance. 1 YEAR or 3 YEAR fixed charge.
Types
Standard RI- upto 75% off on demand
Convertable RI- upto 54% off on demand
Scheduled RI
Spot-enables you to bid whatever price you want for instance capacity, providing even for greater savings if your application have flexible start and end times.
Dedicated Host- Physical EC2 server dedicated for your use. Dedicated use will help you to reduce cost by allowing you to use your existing server-bpund software licenses.
-Suitable for regulatory requirements
-Can be purchased on-demand(hourly)
-with 70% cost off on-demand
-Great for licensing
//DRMCGIFTPX
EBS-Elastic Bean Storage
Amazon EBS will allows you to create stoarge volume and attach them to Amazon Ec2 instance.
Once attached, you can create a file system on top of the volume, run a database or use them in any other way you would use a block device (like a virtual hard disk)
Amazon EBS is placed in specific availablity zone, where they automatically replicated to protect you from the failure of single component.
EBS Volume Types //IOPS -Input Output Operation per seconds
*General purpose SSD (GP2)
-Balances both price and performance
-Ratio of 3 IOPS per GB
-upto 10000 IOPS
*Provisioned IOPS SSD(101)
-Used for high performance SQL server
-10000 to 20000 IOPS
*Throughput Optimized  HDD
-Big Data
-Data warehousing
-Log processing
-Cannot be boot volume
-Low cost for frequently accessed.
*Cold HDD (SC1)
-Lowest cost storage for infrequently accessed.
-File server
-Cannot be a boot volume
*Magnetic(Standard)
_-Lowest stoarage cost

Launching an EC2 instance
One subnet will be available for one availablity zone
Look for Instance type: t2.micro is free
Look for VPC, subnet, instance cost\
Advanced details user data will help to run bootstrap scripts
Security Group are virtual firewalls
Linux command
sudo su-> login as root
yum update-> update all the security patches
yum install httpd -y-> to host a web server
cd /var/www/html
service httpd status-> To check the status
to start a web server-> service httpd start
to make web service is automatically on, use command=> chkconfig httpd on

Security Group
This is actually a virtual firewall which controls traffic to your instances
You can associate one ec2-instance with multiple security group
any change to security group is going to be reflected quickly
Any inbound rules is allowed for outbound as well. They are stateful.
You cant deny a traffic as everything is denied by default.
You cannot ablock specific IP address using security group but you can use network access lists to do the same. ACLs are stateless.

EBS Volume
Root Volume and additional storage EBS volume will be available in same availability region
Except for magnetic storage, we can modify volume of every other EBS volume type
Volume can be done snapshot and can be copied to different region
By default, Root volume will be terminated. Other volumes will be still available
EBS-Virtual Hard disk
Root Volume- where hard disk is installed.
Snapshots are point in time copies of Volumes
Snapshots are incremnetal(to previous snapshot) and exists in S3
To move Ec2 volume from one AZ/Region to another, take a snap or an image of it, then copy it to another AZ
Snapshots of encrypted volume are encrypted automatically.
Unencrypted snapshots can be shared to public or another AWS account.

Snapshots of encrypted volume are encrypted automatically
Volumes restored from encrypted snapshots are encrypted automatically
You can share snapshots 
Snapshots can be made public and can be shared across AWS account

We can select AMI based on below factors
Region(Region and Availability Zone)
Operating System
Architecture(32 bit or 64 bit)
Launch Permissions
Storage for root device (Root Device Volume)
*Instance STore (Ephermal STorage)
*EBS backed volumes
We can stop EBS root volume
We cannot stop instance store root

All AMI are categorized as either backed by Amazon EBS or backed by instance store.
For EBS Volumes: The root device for an instance launched from an AMI is an Amazon EBS volume created from an Amazon EBS snapshot. Volumes can be attched and detached to any instance.
For instance Store Volumes: The rot device for an instance launched from the AMI is an instance store volume created from template stored in Amazon S3. Volumes will not be even listed in Volume section
Instance store volume sometimes called Ephemeral Storage.
Instance store volume cannot be stopped. If the underlying host fails, you will lose your data.
EBS backed instances can be stopped. You will not lose the data on the instance if it is stopped.
You can reboot both, you will not lose your data
By default, both ROOT volumes will be deleted on termination, however with EBS volumes, you can tell AWS to keep the root device volume.

Elastic Load Balancers
It is a virtual machine that balances HTTPS/HTTP request, it recieves. Typically it balances the load that web-servers recieves
There are three types of load balancers
*Application Load Balancer
*Network Load Balancer
*Classic Load Balancer
Application Load Balancer
*Best suited for load balancing of HTTP and HTTPS traffic.
*Operate at Layer7 and are application-ware
*Intelligent, you can create advanced request routing and sending specified requests to specific web servers
Network Load Balancer
*best suited for load balancing of TCO traffic. Operated at Level4.
*Capable of handling millions of request per second, while maintaining ultra-low latencies
*Used for extreme performance
Classic Load Balancer
*Legacy Elastic Load Balancers
*You can load HTTP/HTTPS
*And use Layer-7 specific features, such as X-Forwarded and sticky sessions
*Also use strict Layer4 load balancing for applications that rely on the TCP protocol
Load Balancer Errors
When application stops responding, it throws 504 error. This could be either at the web server layer or at the database layer=> Gateway error of Classic Load balancers
X-Forwarded for Header
used to get public IP address. 
Usually classic load balancer sends the private ip address and using X-Forwarded for Header, we can get
All load balancer will have thier own DNS names

Cloud Watch
Standard Monitoring=5 minutes

aws cli commands
aws configure
aws s3 ls-> to list s3
aws s3 help
aws ec2 describe-instances
to terminate instance-> aws ec2 terminate-instances --instance-ids <<instance-id>>